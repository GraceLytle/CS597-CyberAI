{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019745dc-4c9f-4c4c-b010-c4a8365e5ab8",
   "metadata": {},
   "source": [
    "# Setting Up 4-way-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a40c1-19b7-4ebe-98c8-c3b31b8cc10b",
   "metadata": {},
   "source": [
    "## Original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa2821-82b2-4bad-a39b-dbda2fac32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the string labels ('True' and 'False') with numerical values (0 and 1), which are better suited for machine learning models.\n",
    "df2 = df2[df2['2-way-label'].notnull()]\n",
    "df2['2-way-label'] = df2['2-way-label'].replace({'True': 0, 'False': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d1c5f-724d-4255-ba08-7328c9b5c5e8",
   "metadata": {},
   "source": [
    "## UPDATE\n",
    "The first code block handles only the 2-way-label, filtering out rows where this column is null and mapping the string labels True and False to numerical values (0 and 1). In contrast, the second code block processes both 2-way-label and 4-way-label. It filters rows where either column is null, ensuring the dataset includes valid labels for both classification tasks. Additionally, it maps the string labels in 4-way-label (e.g., True, Mostly True, etc.) to numerical values (0, 1, 2, 3) using a dedicated mapping, while also remapping the 2-way-label in the same way as the first block. The second block is more comprehensive and supports multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37851897-5c52-4dc3-8ada-7517385309ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with null values in labels\n",
    "df2 = df2[df2['2-way-label'].notnull()]\n",
    "df2 = df2[df2['4-way-label'].notnull()]\n",
    "\n",
    "# Replace string labels with numerical values\n",
    "label_mapping_2way = {'True': 0, 'False': 1}\n",
    "label_mapping_4way = {\n",
    "    \"True\": 0,\n",
    "    \"Mostly True\": 1,\n",
    "    \"Mostly False\": 2,\n",
    "    \"False\": 3\n",
    "}\n",
    "\n",
    "df2['2-way-label'] = df2['2-way-label'].replace(label_mapping_2way)\n",
    "df2['4-way-label'] = df2['4-way-label'].replace(label_mapping_4way)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72a2ba-ccee-45fa-93d8-13fa1acc9901",
   "metadata": {},
   "source": [
    "# Visual for new mapping"
   ]
  },
  {
   "attachments": {
    "4e4eec6a-819d-4817-81c8-6a15c7cc2679.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9c4ece95-a054-4133-8106-6e78cccf3b3e",
   "metadata": {},
   "source": [
    "![image.png](attachment:4e4eec6a-819d-4817-81c8-6a15c7cc2679.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3cdaf7-6b46-4aba-9277-dd95e9761def",
   "metadata": {},
   "source": [
    "# Validating that the 4-way-labels are balanced  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009409ed-d449-4970-b91b-f7726fb09518",
   "metadata": {},
   "source": [
    "```\n",
    "# Count the number of items in each label for both datasets\n",
    "train_label_counts = {label: 0 for label in range(4)}\n",
    "val_label_counts = {label: 0 for label in range(4)}\n",
    "\n",
    "for idx in train_indices:\n",
    "    label = dataset[idx][2].item()  # Access the label\n",
    "    train_label_counts[label] += 1\n",
    "\n",
    "for idx in val_indices:\n",
    "    label = dataset[idx][2].item()  # Access the label\n",
    "    val_label_counts[label] += 1\n",
    "\n",
    "print(\"Training samples by label:\")\n",
    "for label, count in train_label_counts.items():\n",
    "    print(f\"Label {label}: {count}\")\n",
    "\n",
    "print(\"Validation samples by label:\")\n",
    "for label, count in val_label_counts.items():\n",
    "    print(f\"Label {label}: {count}\")\n",
    "```\n",
    "```\n",
    "89,273 training samples\n",
    "22,320 validation samples\n",
    "Training samples by label:\n",
    "Label 0: 22620\n",
    "Label 1: 23323\n",
    "Label 2: 22034\n",
    "Label 3: 21296\n",
    "Validation samples by label:\n",
    "Label 0: 5655\n",
    "Label 1: 5831\n",
    "Label 2: 5509\n",
    "Label 3: 5325\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15800d-7161-4f81-b249-2ac6a0aab60c",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fdd948-ab86-4beb-9d07-eed8f7e86c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(torch.int64).to(device)\n",
    "        total_fake_examples += (b_labels == 1).sum().item()\n",
    "        total_true_examples += (b_labels == 0).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acc177-2118-4a28-9844-c0b20c9df018",
   "metadata": {},
   "source": [
    "## UPDATE\n",
    "The difference between the two code blocks lies in how they define and count \"fake\" and \"true\" examples based on the labels (b_labels).\n",
    "\n",
    "First Block:\n",
    "\n",
    "Counts \"fake\" examples as those where b_labels == 1.\n",
    "Counts \"true\" examples as those where b_labels == 0.\n",
    "This is suited for a binary classification task where there are only two possible labels (0 and 1), with 0 representing \"true\" and 1 representing \"fake.\"\n",
    "Second Block:\n",
    "\n",
    "Counts \"fake\" examples as those where b_labels equals 2 or 3 (b_labels == 2 or b_labels == 3).\n",
    "Counts \"true\" examples as those where b_labels equals 0 or 1 (b_labels == 0 or b_labels == 1).\n",
    "This is suited for a multi-class classification task (e.g., 4-way classification), where labels 0 and 1 are treated as \"true,\" and labels 2 and 3 are treated as \"fake.\"\n",
    "The second block expands the classification logic to handle multi-class labels, whereas the first block assumes a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef35520-e2e8-42da-9188-6b86d1d7f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(torch.int64).to(device)\n",
    "        total_fake_examples += ((b_labels == 2) | (b_labels == 3)).sum().item()\n",
    "        total_true_examples += ((b_labels == 0) | (b_labels == 1)).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa452c-608f-4d28-b33d-37b69c98c385",
   "metadata": {},
   "source": [
    "# Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34509965-6eb9-470f-9428-10e16cdd977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 80-20 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "torch.manual_seed(42)  # Set the random seed\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e1ec69-128a-4020-8013-0ead2c85271c",
   "metadata": {},
   "source": [
    "# UPDATE\n",
    "Update for Stratified Split\n",
    "Group Data by Label: Separate your dataset into subsets, one for each label.\n",
    "\n",
    "Split Each Subset: For each label, split the data into 80% training and 20% validation\n",
    "Maintain Proportions: Ensures that the proportion of samples for each label in training and validation is consistent with the overall dataset distribution.\n",
    "Avoid Bias: Prevents scenarios where certain labels are overrepresented or missing in either the training or validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cefc0-16d9-47b4-9e7c-639af9ac9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Group data by label\n",
    "label_indices = {label: [] for label in range(4)}  # Assuming labels are [0, 1, 2, 3]\n",
    "for idx, (_, _, label) in enumerate(dataset):\n",
    "    label_indices[label.item()].append(idx)\n",
    "\n",
    "# Perform stratified split\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "\n",
    "for label, indices in label_indices.items():\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        indices, test_size=0.2, random_state=42  # 80-20 split\n",
    "    )\n",
    "    train_indices.extend(train_idx)\n",
    "    val_indices.extend(val_idx)\n",
    "\n",
    "# Create train and validation datasets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "print('{:>5,} validation samples'.format(len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ce52bd-308c-4f6d-a520-e3f395ba7e78",
   "metadata": {},
   "source": [
    " # Initial Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dcbc55-c834-4cf8-be5a-8552f5a112e0",
   "metadata": {},
   "source": [
    "```\n",
    "======== Epoch 1 / 4 ========\n",
    "Training...\n",
    "  Batch    40  of  2,790.    Elapsed: 0:00:13. Training loss. 0.6781517267227173 Num fake examples 626 Num true examples 654\n",
    "  Batch    80  of  2,790.    Elapsed: 0:00:26. Training loss. 0.6263445615768433 Num fake examples 1272 Num true examples 1288\n",
    "  Batch   120  of  2,790.    Elapsed: 0:00:40. Training loss. 0.5697269439697266 Num fake examples 1901 Num true examples 1939\n",
    "  Batch   160  of  2,790.    Elapsed: 0:00:55. Training loss. 0.5543661713600159 Num fake examples 2555 Num true examples 2565\n",
    "  Batch   200  of  2,790.    Elapsed: 0:01:09. Training loss. 0.5478495359420776 Num fake examples 3178 Num true examples 3222\n",
    "  Batch   240  of  2,790.    Elapsed: 0:01:24. Training loss. 0.544278621673584 Num fake examples 3801 Num true examples 3879\n",
    "  Batch   280  of  2,790.    Elapsed: 0:01:38. Training loss. 0.5507753491401672 Num fake examples 4440 Num true examples 4520\n",
    "  Batch   320  of  2,790.    Elapsed: 0:01:53. Training loss. 0.4484952390193939 Num fake examples 5086 Num true examples 5154\n",
    "  Batch   360  of  2,790.    Elapsed: 0:02:07. Training loss. 0.5034416317939758 Num fake examples 5704 Num true examples 5816\n",
    "  Batch   400  of  2,790.    Elapsed: 0:02:22. Training loss. 0.46799248456954956 Num fake examples 6360 Num true examples 6440\n",
    "  Batch   440  of  2,790.    Elapsed: 0:02:36. Training loss. 0.3932987451553345 Num fake examples 7013 Num true examples 7067\n",
    "  Batch   480  of  2,790.    Elapsed: 0:02:51. Training loss. 0.4610861539840698 Num fake examples 7643 Num true examples 7717\n",
    "  Batch   520  of  2,790.    Elapsed: 0:03:05. Training loss. 0.4305168390274048 Num fake examples 8253 Num true examples 8387\n",
    "  Batch   560  of  2,790.    Elapsed: 0:03:20. Training loss. 0.46817123889923096 Num fake examples 8881 Num true examples 9039\n",
    "  Batch   600  of  2,790.    Elapsed: 0:03:34. Training loss. 0.4384930729866028 Num fake examples 9526 Num true examples 9674\n",
    "  Batch   640  of  2,790.    Elapsed: 0:03:48. Training loss. 0.3682554364204407 Num fake examples 10166 Num true examples 10314\n",
    "  Batch   680  of  2,790.    Elapsed: 0:04:03. Training loss. 0.37608587741851807 Num fake examples 10768 Num true examples 10992\n",
    "  Batch   720  of  2,790.    Elapsed: 0:04:17. Training loss. 0.3884163200855255 Num fake examples 11382 Num true examples 11658\n",
    "  Batch   760  of  2,790.    Elapsed: 0:04:32. Training loss. 0.41368430852890015 Num fake examples 11996 Num true examples 12324\n",
    "  Batch   800  of  2,790.    Elapsed: 0:04:46. Training loss. 0.41437166929244995 Num fake examples 12618 Num true examples 12982\n",
    "  Batch   840  of  2,790.    Elapsed: 0:05:00. Training loss. 0.37055325508117676 Num fake examples 13228 Num true examples 13652\n",
    "  Batch   880  of  2,790.    Elapsed: 0:05:15. Training loss. 0.37747693061828613 Num fake examples 13863 Num true examples 14297\n",
    "  Batch   920  of  2,790.    Elapsed: 0:05:29. Training loss. 0.3780974745750427 Num fake examples 14462 Num true examples 14978\n",
    "  Batch   960  of  2,790.    Elapsed: 0:05:43. Training loss. 0.38515764474868774 Num fake examples 15086 Num true examples 15634\n",
    "  Batch 1,000  of  2,790.    Elapsed: 0:05:58. Training loss. 0.3638369143009186 Num fake examples 15746 Num true examples 16254\n",
    "  Batch 1,040  of  2,790.    Elapsed: 0:06:12. Training loss. 0.4384477138519287 Num fake examples 16368 Num true examples 16912\n",
    "  Batch 1,080  of  2,790.    Elapsed: 0:06:27. Training loss. 0.3641906976699829 Num fake examples 17027 Num true examples 17533\n",
    "  Batch 1,120  of  2,790.    Elapsed: 0:06:41. Training loss. 0.3745090961456299 Num fake examples 17652 Num true examples 18188\n",
    "  Batch 1,160  of  2,790.    Elapsed: 0:06:55. Training loss. 0.39855149388313293 Num fake examples 18270 Num true examples 18850\n",
    "  Batch 1,200  of  2,790.    Elapsed: 0:07:10. Training loss. 0.38893699645996094 Num fake examples 18878 Num true examples 19522\n",
    "  Batch 1,240  of  2,790.    Elapsed: 0:07:24. Training loss. 0.3776392340660095 Num fake examples 19504 Num true examples 20176\n",
    "  Batch 1,280  of  2,790.    Elapsed: 0:07:39. Training loss. 0.36323657631874084 Num fake examples 20154 Num true examples 20806\n",
    "  Batch 1,320  of  2,790.    Elapsed: 0:07:53. Training loss. 0.3542647957801819 Num fake examples 20759 Num true examples 21481\n",
    "  Batch 1,360  of  2,790.    Elapsed: 0:08:07. Training loss. 0.41861966252326965 Num fake examples 21388 Num true examples 22132\n",
    "  Batch 1,400  of  2,790.    Elapsed: 0:08:22. Training loss. 0.3559756577014923 Num fake examples 21979 Num true examples 22821\n",
    "  Batch 1,440  of  2,790.    Elapsed: 0:08:36. Training loss. 0.3806708753108978 Num fake examples 22588 Num true examples 23492\n",
    "  Batch 1,480  of  2,790.    Elapsed: 0:08:51. Training loss. 0.3910355567932129 Num fake examples 23208 Num true examples 24152\n",
    "  Batch 1,520  of  2,790.    Elapsed: 0:09:05. Training loss. 0.36069151759147644 Num fake examples 23826 Num true examples 24814\n",
    "  Batch 1,560  of  2,790.    Elapsed: 0:09:19. Training loss. 0.38510432839393616 Num fake examples 24461 Num true examples 25459\n",
    "  Batch 1,600  of  2,790.    Elapsed: 0:09:34. Training loss. 0.4125412702560425 Num fake examples 25072 Num true examples 26128\n",
    "  Batch 1,640  of  2,790.    Elapsed: 0:09:48. Training loss. 0.4777345657348633 Num fake examples 25652 Num true examples 26828\n",
    "  Batch 1,680  of  2,790.    Elapsed: 0:10:03. Training loss. 0.35409289598464966 Num fake examples 26291 Num true examples 27469\n",
    "  Batch 1,720  of  2,790.    Elapsed: 0:10:17. Training loss. 0.3476731777191162 Num fake examples 26879 Num true examples 28161\n",
    "  Batch 1,760  of  2,790.    Elapsed: 0:10:31. Training loss. 0.3598805069923401 Num fake examples 27506 Num true examples 28814\n",
    "  Batch 1,800  of  2,790.    Elapsed: 0:10:46. Training loss. 0.41538065671920776 Num fake examples 28093 Num true examples 29507\n",
    "  Batch 1,840  of  2,790.    Elapsed: 0:11:00. Training loss. 0.3503253757953644 Num fake examples 28729 Num true examples 30151\n",
    "  Batch 1,880  of  2,790.    Elapsed: 0:11:15. Training loss. 0.38393330574035645 Num fake examples 29345 Num true examples 30815\n",
    "  Batch 1,920  of  2,790.    Elapsed: 0:11:29. Training loss. 0.39194661378860474 Num fake examples 29972 Num true examples 31468\n",
    "  Batch 1,960  of  2,790.    Elapsed: 0:11:43. Training loss. 0.4044085741043091 Num fake examples 30579 Num true examples 32141\n",
    "  Batch 2,000  of  2,790.    Elapsed: 0:11:58. Training loss. 0.4146804213523865 Num fake examples 31200 Num true examples 32800\n",
    "  Batch 2,040  of  2,790.    Elapsed: 0:12:12. Training loss. 0.34644967317581177 Num fake examples 31814 Num true examples 33466\n",
    "  Batch 2,080  of  2,790.    Elapsed: 0:12:27. Training loss. 0.44603127241134644 Num fake examples 32437 Num true examples 34123\n",
    "  Batch 2,120  of  2,790.    Elapsed: 0:12:41. Training loss. 0.3640744686126709 Num fake examples 33061 Num true examples 34779\n",
    "  Batch 2,160  of  2,790.    Elapsed: 0:12:55. Training loss. 0.401137113571167 Num fake examples 33684 Num true examples 35436\n",
    "  Batch 2,200  of  2,790.    Elapsed: 0:13:10. Training loss. 0.4253925085067749 Num fake examples 34322 Num true examples 36078\n",
    "  Batch 2,240  of  2,790.    Elapsed: 0:13:24. Training loss. 0.44358253479003906 Num fake examples 34957 Num true examples 36723\n",
    "  Batch 2,280  of  2,790.    Elapsed: 0:13:39. Training loss. 0.3930598497390747 Num fake examples 35570 Num true examples 37390\n",
    "  Batch 2,320  of  2,790.    Elapsed: 0:13:53. Training loss. 0.4092983305454254 Num fake examples 36210 Num true examples 38030\n",
    "  Batch 2,360  of  2,790.    Elapsed: 0:14:07. Training loss. 0.38426828384399414 Num fake examples 36824 Num true examples 38696\n",
    "  Batch 2,400  of  2,790.    Elapsed: 0:14:22. Training loss. 0.36689963936805725 Num fake examples 37449 Num true examples 39351\n",
    "  Batch 2,440  of  2,790.    Elapsed: 0:14:36. Training loss. 0.40770453214645386 Num fake examples 38097 Num true examples 39983\n",
    "  Batch 2,480  of  2,790.    Elapsed: 0:14:51. Training loss. 0.4199489951133728 Num fake examples 38710 Num true examples 40650\n",
    "  Batch 2,520  of  2,790.    Elapsed: 0:15:05. Training loss. 0.41935622692108154 Num fake examples 39333 Num true examples 41307\n",
    "  Batch 2,560  of  2,790.    Elapsed: 0:15:19. Training loss. 0.3839372396469116 Num fake examples 39946 Num true examples 41974\n",
    "  Batch 2,600  of  2,790.    Elapsed: 0:15:34. Training loss. 0.35433733463287354 Num fake examples 40564 Num true examples 42636\n",
    "  Batch 2,640  of  2,790.    Elapsed: 0:15:48. Training loss. 0.3843673765659332 Num fake examples 41155 Num true examples 43325\n",
    "  Batch 2,680  of  2,790.    Elapsed: 0:16:03. Training loss. 0.3867602050304413 Num fake examples 41765 Num true examples 43995\n",
    "  Batch 2,720  of  2,790.    Elapsed: 0:16:17. Training loss. 0.38932496309280396 Num fake examples 42362 Num true examples 44678\n",
    "  Batch 2,760  of  2,790.    Elapsed: 0:16:31. Training loss. 0.36200636625289917 Num fake examples 43003 Num true examples 45317\n",
    "\n",
    "  Average training loss: 0.42\n",
    "  Training epcoh took: 0:16:42\n",
    "\n",
    "Running Validation...\n",
    "  Accuracy: 0.49\n",
    "  Validation Loss: 0.39\n",
    "  Validation took: 0:01:41\n",
    "\n",
    "======== Epoch 2 / 4 ========\n",
    "Training...\n",
    "  Batch    40  of  2,790.    Elapsed: 0:00:14. Training loss. 0.3862661123275757 Num fake examples 617 Num true examples 663\n",
    "  Batch    80  of  2,790.    Elapsed: 0:00:28. Training loss. 0.40898340940475464 Num fake examples 1287 Num true examples 1273\n",
    "  Batch   120  of  2,790.    Elapsed: 0:00:43. Training loss. 0.382870614528656 Num fake examples 1891 Num true examples 1949\n",
    "  Batch   160  of  2,790.    Elapsed: 0:00:57. Training loss. 0.42571502923965454 Num fake examples 2517 Num true examples 2603\n",
    "  Batch   200  of  2,790.    Elapsed: 0:01:11. Training loss. 0.39149901270866394 Num fake examples 3140 Num true examples 3260\n",
    "  Batch   240  of  2,790.    Elapsed: 0:01:26. Training loss. 0.38351964950561523 Num fake examples 3738 Num true examples 3942\n",
    "  Batch   280  of  2,790.    Elapsed: 0:01:40. Training loss. 0.39729368686676025 Num fake examples 4364 Num true examples 4596\n",
    "  Batch   320  of  2,790.    Elapsed: 0:01:54. Training loss. 0.4096594750881195 Num fake examples 4957 Num true examples 5283\n",
    "  Batch   360  of  2,790.    Elapsed: 0:02:09. Training loss. 0.3898468613624573 Num fake examples 5579 Num true examples 5941\n",
    "  Batch   400  of  2,790.    Elapsed: 0:02:23. Training loss. 0.4085986912250519 Num fake examples 6208 Num true examples 6592\n",
    "  Batch   440  of  2,790.    Elapsed: 0:02:38. Training loss. 0.4030081629753113 Num fake examples 6819 Num true examples 7261\n",
    "  Batch   480  of  2,790.    Elapsed: 0:02:52. Training loss. 0.42958420515060425 Num fake examples 7450 Num true examples 7910\n",
    "  Batch   520  of  2,790.    Elapsed: 0:03:06. Training loss. 0.37894532084465027 Num fake examples 8077 Num true examples 8563\n",
    "  Batch   560  of  2,790.    Elapsed: 0:03:21. Training loss. 0.43188297748565674 Num fake examples 8733 Num true examples 9187\n",
    "  Batch   600  of  2,790.    Elapsed: 0:03:35. Training loss. 0.41569072008132935 Num fake examples 9351 Num true examples 9849\n",
    "  Batch   640  of  2,790.    Elapsed: 0:03:50. Training loss. 0.3587392568588257 Num fake examples 9980 Num true examples 10500\n",
    "  Batch   680  of  2,790.    Elapsed: 0:04:04. Training loss. 0.5044633150100708 Num fake examples 10592 Num true examples 11168\n",
    "  Batch   720  of  2,790.    Elapsed: 0:04:18. Training loss. 0.38499778509140015 Num fake examples 11206 Num true examples 11834\n",
    "  Batch   760  of  2,790.    Elapsed: 0:04:33. Training loss. 0.44871851801872253 Num fake examples 11817 Num true examples 12503\n",
    "  Batch   800  of  2,790.    Elapsed: 0:04:47. Training loss. 0.3398191034793854 Num fake examples 12440 Num true examples 13160\n",
    "  Batch   840  of  2,790.    Elapsed: 0:05:01. Training loss. 0.41533541679382324 Num fake examples 13039 Num true examples 13841\n",
    "  Batch   880  of  2,790.    Elapsed: 0:05:16. Training loss. 0.36297762393951416 Num fake examples 13682 Num true examples 14478\n",
    "  Batch   920  of  2,790.    Elapsed: 0:05:30. Training loss. 0.39462000131607056 Num fake examples 14326 Num true examples 15114\n",
    "  Batch   960  of  2,790.    Elapsed: 0:05:45. Training loss. 0.3537713885307312 Num fake examples 14958 Num true examples 15762\n",
    "  Batch 1,000  of  2,790.    Elapsed: 0:05:59. Training loss. 0.3590540289878845 Num fake examples 15589 Num true examples 16411\n",
    "  Batch 1,040  of  2,790.    Elapsed: 0:06:13. Training loss. 0.41121906042099 Num fake examples 16198 Num true examples 17082\n",
    "  Batch 1,080  of  2,790.    Elapsed: 0:06:28. Training loss. 0.3936556577682495 Num fake examples 16843 Num true examples 17717\n",
    "  Batch 1,120  of  2,790.    Elapsed: 0:06:42. Training loss. 0.39968013763427734 Num fake examples 17449 Num true examples 18391\n",
    "  Batch 1,160  of  2,790.    Elapsed: 0:06:56. Training loss. 0.37805408239364624 Num fake examples 18082 Num true examples 19038\n",
    "  Batch 1,200  of  2,790.    Elapsed: 0:07:11. Training loss. 0.37859636545181274 Num fake examples 18716 Num true examples 19684\n",
    "  Batch 1,240  of  2,790.    Elapsed: 0:07:25. Training loss. 0.37814098596572876 Num fake examples 19394 Num true examples 20286\n",
    "  Batch 1,280  of  2,790.    Elapsed: 0:07:39. Training loss. 0.3600773811340332 Num fake examples 20038 Num true examples 20922\n",
    "  Batch 1,320  of  2,790.    Elapsed: 0:07:54. Training loss. 0.39220044016838074 Num fake examples 20683 Num true examples 21557\n",
    "  Batch 1,360  of  2,790.    Elapsed: 0:08:08. Training loss. 0.5214897394180298 Num fake examples 21318 Num true examples 22202\n",
    "  Batch 1,400  of  2,790.    Elapsed: 0:08:23. Training loss. 0.35520321130752563 Num fake examples 21936 Num true examples 22864\n",
    "  Batch 1,440  of  2,790.    Elapsed: 0:08:37. Training loss. 0.38692015409469604 Num fake examples 22526 Num true examples 23554\n",
    "  Batch 1,480  of  2,790.    Elapsed: 0:08:51. Training loss. 0.35638540983200073 Num fake examples 23187 Num true examples 24173\n",
    "  Batch 1,520  of  2,790.    Elapsed: 0:09:06. Training loss. 0.3871668577194214 Num fake examples 23798 Num true examples 24842\n",
    "  Batch 1,560  of  2,790.    Elapsed: 0:09:20. Training loss. 0.3557471036911011 Num fake examples 24429 Num true examples 25491\n",
    "  Batch 1,600  of  2,790.    Elapsed: 0:09:34. Training loss. 0.35332226753234863 Num fake examples 25031 Num true examples 26169\n",
    "  Batch 1,640  of  2,790.    Elapsed: 0:09:49. Training loss. 0.44768184423446655 Num fake examples 25636 Num true examples 26844\n",
    "  Batch 1,680  of  2,790.    Elapsed: 0:10:03. Training loss. 0.3834673762321472 Num fake examples 26257 Num true examples 27503\n",
    "  Batch 1,720  of  2,790.    Elapsed: 0:10:17. Training loss. 0.4088781476020813 Num fake examples 26865 Num true examples 28175\n",
    "  Batch 1,760  of  2,790.    Elapsed: 0:10:32. Training loss. 0.3557737171649933 Num fake examples 27497 Num true examples 28823\n",
    "  Batch 1,800  of  2,790.    Elapsed: 0:10:46. Training loss. 0.3579977750778198 Num fake examples 28084 Num true examples 29516\n",
    "  Batch 1,840  of  2,790.    Elapsed: 0:11:00. Training loss. 0.392944872379303 Num fake examples 28695 Num true examples 30185\n",
    "  Batch 1,880  of  2,790.    Elapsed: 0:11:15. Training loss. 0.3550136983394623 Num fake examples 29309 Num true examples 30851\n",
    "  Batch 1,920  of  2,790.    Elapsed: 0:11:29. Training loss. 0.4261569380760193 Num fake examples 29939 Num true examples 31501\n",
    "  Batch 1,960  of  2,790.    Elapsed: 0:11:44. Training loss. 0.3647420406341553 Num fake examples 30557 Num true examples 32163\n",
    "  Batch 2,000  of  2,790.    Elapsed: 0:11:58. Training loss. 0.38166195154190063 Num fake examples 31161 Num true examples 32839\n",
    "  Batch 2,040  of  2,790.    Elapsed: 0:12:12. Training loss. 0.4088525176048279 Num fake examples 31815 Num true examples 33465\n",
    "  Batch 2,080  of  2,790.    Elapsed: 0:12:27. Training loss. 0.3502781093120575 Num fake examples 32414 Num true examples 34146\n",
    "  Batch 2,120  of  2,790.    Elapsed: 0:12:41. Training loss. 0.35526344180107117 Num fake examples 33052 Num true examples 34788\n",
    "  Batch 2,160  of  2,790.    Elapsed: 0:12:55. Training loss. 0.3896411657333374 Num fake examples 33683 Num true examples 35437\n",
    "  Batch 2,200  of  2,790.    Elapsed: 0:13:10. Training loss. 0.35127779841423035 Num fake examples 34319 Num true examples 36081\n",
    "  Batch 2,240  of  2,790.    Elapsed: 0:13:24. Training loss. 0.40530526638031006 Num fake examples 34923 Num true examples 36757\n",
    "  Batch 2,280  of  2,790.    Elapsed: 0:13:39. Training loss. 0.40398645401000977 Num fake examples 35538 Num true examples 37422\n",
    "  Batch 2,320  of  2,790.    Elapsed: 0:13:53. Training loss. 0.446648508310318 Num fake examples 36173 Num true examples 38067\n",
    "  Batch 2,360  of  2,790.    Elapsed: 0:14:07. Training loss. 0.43142029643058777 Num fake examples 36792 Num true examples 38728\n",
    "  Batch 2,400  of  2,790.    Elapsed: 0:14:22. Training loss. 0.37644386291503906 Num fake examples 37390 Num true examples 39410\n",
    "  Batch 2,440  of  2,790.    Elapsed: 0:14:36. Training loss. 0.40662646293640137 Num fake examples 38031 Num true examples 40049\n",
    "  Batch 2,480  of  2,790.    Elapsed: 0:14:50. Training loss. 0.3785971999168396 Num fake examples 38657 Num true examples 40703\n",
    "  Batch 2,520  of  2,790.    Elapsed: 0:15:05. Training loss. 0.38902974128723145 Num fake examples 39280 Num true examples 41360\n",
    "  Batch 2,560  of  2,790.    Elapsed: 0:15:19. Training loss. 0.4520447254180908 Num fake examples 39903 Num true examples 42017\n",
    "  Batch 2,600  of  2,790.    Elapsed: 0:15:34. Training loss. 0.41636818647384644 Num fake examples 40524 Num true examples 42676\n",
    "  Batch 2,640  of  2,790.    Elapsed: 0:15:48. Training loss. 0.38141757249832153 Num fake examples 41141 Num true examples 43339\n",
    "  Batch 2,680  of  2,790.    Elapsed: 0:16:02. Training loss. 0.43812838196754456 Num fake examples 41759 Num true examples 44001\n",
    "  Batch 2,720  of  2,790.    Elapsed: 0:16:17. Training loss. 0.3903948664665222 Num fake examples 42388 Num true examples 44652\n",
    "  Batch 2,760  of  2,790.    Elapsed: 0:16:31. Training loss. 0.4574216604232788 Num fake examples 43017 Num true examples 45303\n",
    "\n",
    "  Average training loss: 0.39\n",
    "  Training epcoh took: 0:16:42\n",
    "\n",
    "Running Validation...\n",
    "  Accuracy: 0.50\n",
    "  Validation Loss: 0.38\n",
    "  Validation took: 0:01:41\n",
    "\n",
    "======== Epoch 3 / 4 ========\n",
    "Training...\n",
    "  Batch    40  of  2,790.    Elapsed: 0:00:14. Training loss. 0.42790764570236206 Num fake examples 599 Num true examples 681\n",
    "  Batch    80  of  2,790.    Elapsed: 0:00:28. Training loss. 0.38288629055023193 Num fake examples 1232 Num true examples 1328\n",
    "  Batch   120  of  2,790.    Elapsed: 0:00:43. Training loss. 0.3820754289627075 Num fake examples 1860 Num true examples 1980\n",
    "  Batch   160  of  2,790.    Elapsed: 0:00:57. Training loss. 0.3766656816005707 Num fake examples 2500 Num true examples 2620\n",
    "  Batch   200  of  2,790.    Elapsed: 0:01:11. Training loss. 0.3779357671737671 Num fake examples 3144 Num true examples 3256\n",
    "  Batch   240  of  2,790.    Elapsed: 0:01:26. Training loss. 0.37868842482566833 Num fake examples 3807 Num true examples 3873\n",
    "  Batch   280  of  2,790.    Elapsed: 0:01:40. Training loss. 0.4274519085884094 Num fake examples 4447 Num true examples 4513\n",
    "  Batch   320  of  2,790.    Elapsed: 0:01:55. Training loss. 0.38417065143585205 Num fake examples 5078 Num true examples 5162\n",
    "  Batch   360  of  2,790.    Elapsed: 0:02:09. Training loss. 0.3894050121307373 Num fake examples 5697 Num true examples 5823\n",
    "  Batch   400  of  2,790.    Elapsed: 0:02:23. Training loss. 0.43271225690841675 Num fake examples 6335 Num true examples 6465\n",
    "  Batch   440  of  2,790.    Elapsed: 0:02:38. Training loss. 0.3801209330558777 Num fake examples 6936 Num true examples 7144\n",
    "  Batch   480  of  2,790.    Elapsed: 0:02:52. Training loss. 0.3919796347618103 Num fake examples 7584 Num true examples 7776\n",
    "  Batch   520  of  2,790.    Elapsed: 0:03:06. Training loss. 0.377444326877594 Num fake examples 8212 Num true examples 8428\n",
    "  Batch   560  of  2,790.    Elapsed: 0:03:21. Training loss. 0.3462916612625122 Num fake examples 8797 Num true examples 9123\n",
    "  Batch   600  of  2,790.    Elapsed: 0:03:35. Training loss. 0.36060935258865356 Num fake examples 9415 Num true examples 9785\n",
    "  Batch   640  of  2,790.    Elapsed: 0:03:50. Training loss. 0.4455009698867798 Num fake examples 10023 Num true examples 10457\n",
    "  Batch   680  of  2,790.    Elapsed: 0:04:04. Training loss. 0.3751096725463867 Num fake examples 10660 Num true examples 11100\n",
    "  Batch   720  of  2,790.    Elapsed: 0:04:18. Training loss. 0.3795713186264038 Num fake examples 11294 Num true examples 11746\n",
    "  Batch   760  of  2,790.    Elapsed: 0:04:33. Training loss. 0.395809143781662 Num fake examples 11925 Num true examples 12395\n",
    "  Batch   800  of  2,790.    Elapsed: 0:04:47. Training loss. 0.36231130361557007 Num fake examples 12554 Num true examples 13046\n",
    "  Batch   840  of  2,790.    Elapsed: 0:05:01. Training loss. 0.355959951877594 Num fake examples 13170 Num true examples 13710\n",
    "  Batch   880  of  2,790.    Elapsed: 0:05:16. Training loss. 0.3540652394294739 Num fake examples 13777 Num true examples 14383\n",
    "  Batch   920  of  2,790.    Elapsed: 0:05:30. Training loss. 0.4145311415195465 Num fake examples 14444 Num true examples 14996\n",
    "  Batch   960  of  2,790.    Elapsed: 0:05:45. Training loss. 0.38638433814048767 Num fake examples 15077 Num true examples 15643\n",
    "  Batch 1,000  of  2,790.    Elapsed: 0:05:59. Training loss. 0.3895276188850403 Num fake examples 15683 Num true examples 16317\n",
    "  Batch 1,040  of  2,790.    Elapsed: 0:06:13. Training loss. 0.34967076778411865 Num fake examples 16315 Num true examples 16965\n",
    "  Batch 1,080  of  2,790.    Elapsed: 0:06:28. Training loss. 0.4427236020565033 Num fake examples 16939 Num true examples 17621\n",
    "  Batch 1,120  of  2,790.    Elapsed: 0:06:42. Training loss. 0.3735758662223816 Num fake examples 17525 Num true examples 18315\n",
    "  Batch 1,160  of  2,790.    Elapsed: 0:06:57. Training loss. 0.34933918714523315 Num fake examples 18159 Num true examples 18961\n",
    "  Batch 1,200  of  2,790.    Elapsed: 0:07:11. Training loss. 0.4135999381542206 Num fake examples 18790 Num true examples 19610\n",
    "  Batch 1,240  of  2,790.    Elapsed: 0:07:25. Training loss. 0.35876575112342834 Num fake examples 19389 Num true examples 20291\n",
    "  Batch 1,280  of  2,790.    Elapsed: 0:07:40. Training loss. 0.3523712754249573 Num fake examples 20036 Num true examples 20924\n",
    "  Batch 1,320  of  2,790.    Elapsed: 0:07:54. Training loss. 0.4569893777370453 Num fake examples 20662 Num true examples 21578\n",
    "  Batch 1,360  of  2,790.    Elapsed: 0:08:09. Training loss. 0.38683053851127625 Num fake examples 21286 Num true examples 22234\n",
    "  Batch 1,400  of  2,790.    Elapsed: 0:08:23. Training loss. 0.41372716426849365 Num fake examples 21906 Num true examples 22894\n",
    "  Batch 1,440  of  2,790.    Elapsed: 0:08:37. Training loss. 0.37208646535873413 Num fake examples 22537 Num true examples 23543\n",
    "  Batch 1,480  of  2,790.    Elapsed: 0:08:52. Training loss. 0.358352392911911 Num fake examples 23148 Num true examples 24212\n",
    "  Batch 1,520  of  2,790.    Elapsed: 0:09:06. Training loss. 0.39068907499313354 Num fake examples 23774 Num true examples 24866\n",
    "  Batch 1,560  of  2,790.    Elapsed: 0:09:21. Training loss. 0.4038681089878082 Num fake examples 24434 Num true examples 25486\n",
    "  Batch 1,600  of  2,790.    Elapsed: 0:09:35. Training loss. 0.40373694896698 Num fake examples 25035 Num true examples 26165\n",
    "  Batch 1,640  of  2,790.    Elapsed: 0:09:49. Training loss. 0.4131893217563629 Num fake examples 25667 Num true examples 26813\n",
    "  Batch 1,680  of  2,790.    Elapsed: 0:10:04. Training loss. 0.44707244634628296 Num fake examples 26301 Num true examples 27459\n",
    "  Batch 1,720  of  2,790.    Elapsed: 0:10:18. Training loss. 0.3981790542602539 Num fake examples 26930 Num true examples 28110\n",
    "  Batch 1,760  of  2,790.    Elapsed: 0:10:33. Training loss. 0.3605612814426422 Num fake examples 27567 Num true examples 28753\n",
    "  Batch 1,800  of  2,790.    Elapsed: 0:10:47. Training loss. 0.3774604797363281 Num fake examples 28151 Num true examples 29449\n",
    "  Batch 1,840  of  2,790.    Elapsed: 0:11:01. Training loss. 0.3385671079158783 Num fake examples 28768 Num true examples 30112\n",
    "  Batch 1,880  of  2,790.    Elapsed: 0:11:16. Training loss. 0.3907296657562256 Num fake examples 29363 Num true examples 30797\n",
    "  Batch 1,920  of  2,790.    Elapsed: 0:11:30. Training loss. 0.35141804814338684 Num fake examples 29977 Num true examples 31463\n",
    "  Batch 1,960  of  2,790.    Elapsed: 0:11:45. Training loss. 0.3568075895309448 Num fake examples 30570 Num true examples 32150\n",
    "  Batch 2,000  of  2,790.    Elapsed: 0:11:59. Training loss. 0.395846962928772 Num fake examples 31188 Num true examples 32812\n",
    "  Batch 2,040  of  2,790.    Elapsed: 0:12:13. Training loss. 0.3489075005054474 Num fake examples 31814 Num true examples 33466\n",
    "  Batch 2,080  of  2,790.    Elapsed: 0:12:28. Training loss. 0.35141339898109436 Num fake examples 32428 Num true examples 34132\n",
    "  Batch 2,120  of  2,790.    Elapsed: 0:12:42. Training loss. 0.34870022535324097 Num fake examples 33054 Num true examples 34786\n",
    "  Batch 2,160  of  2,790.    Elapsed: 0:12:57. Training loss. 0.3635905385017395 Num fake examples 33664 Num true examples 35456\n",
    "  Batch 2,200  of  2,790.    Elapsed: 0:13:11. Training loss. 0.3654181659221649 Num fake examples 34307 Num true examples 36093\n",
    "  Batch 2,240  of  2,790.    Elapsed: 0:13:25. Training loss. 0.356902152299881 Num fake examples 34906 Num true examples 36774\n",
    "  Batch 2,280  of  2,790.    Elapsed: 0:13:40. Training loss. 0.4056021571159363 Num fake examples 35550 Num true examples 37410\n",
    "  Batch 2,320  of  2,790.    Elapsed: 0:13:54. Training loss. 0.34676843881607056 Num fake examples 36169 Num true examples 38071\n",
    "  Batch 2,360  of  2,790.    Elapsed: 0:14:09. Training loss. 0.4274623692035675 Num fake examples 36778 Num true examples 38742\n",
    "  Batch 2,400  of  2,790.    Elapsed: 0:14:23. Training loss. 0.4058724641799927 Num fake examples 37387 Num true examples 39413\n",
    "  Batch 2,440  of  2,790.    Elapsed: 0:14:37. Training loss. 0.38374704122543335 Num fake examples 37980 Num true examples 40100\n",
    "  Batch 2,480  of  2,790.    Elapsed: 0:14:52. Training loss. 0.38112106919288635 Num fake examples 38609 Num true examples 40751\n",
    "  Batch 2,520  of  2,790.    Elapsed: 0:15:06. Training loss. 0.3804210126399994 Num fake examples 39258 Num true examples 41382\n",
    "  Batch 2,560  of  2,790.    Elapsed: 0:15:21. Training loss. 0.37290796637535095 Num fake examples 39871 Num true examples 42049\n",
    "  Batch 2,600  of  2,790.    Elapsed: 0:15:35. Training loss. 0.3566984236240387 Num fake examples 40516 Num true examples 42684\n",
    "  Batch 2,640  of  2,790.    Elapsed: 0:15:49. Training loss. 0.35974228382110596 Num fake examples 41127 Num true examples 43353\n",
    "  Batch 2,680  of  2,790.    Elapsed: 0:16:04. Training loss. 0.3645686209201813 Num fake examples 41756 Num true examples 44004\n",
    "  Batch 2,720  of  2,790.    Elapsed: 0:16:18. Training loss. 0.3656904995441437 Num fake examples 42353 Num true examples 44687\n",
    "  Batch 2,760  of  2,790.    Elapsed: 0:16:33. Training loss. 0.4175812602043152 Num fake examples 42973 Num true examples 45347\n",
    "\n",
    "  Average training loss: 0.38\n",
    "  Training epcoh took: 0:16:43\n",
    "\n",
    "Running Validation...\n",
    "  Accuracy: 0.51\n",
    "  Validation Loss: 0.38\n",
    "  Validation took: 0:01:41\n",
    "\n",
    "======== Epoch 4 / 4 ========\n",
    "Training...\n",
    "  Batch    40  of  2,790.    Elapsed: 0:00:14. Training loss. 0.4225565195083618 Num fake examples 658 Num true examples 622\n",
    "  Batch    80  of  2,790.    Elapsed: 0:00:28. Training loss. 0.3935213088989258 Num fake examples 1311 Num true examples 1249\n",
    "  Batch   120  of  2,790.    Elapsed: 0:00:43. Training loss. 0.38003093004226685 Num fake examples 1901 Num true examples 1939\n",
    "  Batch   160  of  2,790.    Elapsed: 0:00:57. Training loss. 0.4252457022666931 Num fake examples 2551 Num true examples 2569\n",
    "  Batch   200  of  2,790.    Elapsed: 0:01:11. Training loss. 0.36375489830970764 Num fake examples 3166 Num true examples 3234\n",
    "  Batch   240  of  2,790.    Elapsed: 0:01:26. Training loss. 0.37673771381378174 Num fake examples 3803 Num true examples 3877\n",
    "  Batch   280  of  2,790.    Elapsed: 0:01:40. Training loss. 0.4080820679664612 Num fake examples 4441 Num true examples 4519\n",
    "  Batch   320  of  2,790.    Elapsed: 0:01:54. Training loss. 0.36783474683761597 Num fake examples 5069 Num true examples 5171\n",
    "  Batch   360  of  2,790.    Elapsed: 0:02:09. Training loss. 0.42126113176345825 Num fake examples 5707 Num true examples 5813\n",
    "  Batch   400  of  2,790.    Elapsed: 0:02:23. Training loss. 0.35212191939353943 Num fake examples 6333 Num true examples 6467\n",
    "  Batch   440  of  2,790.    Elapsed: 0:02:37. Training loss. 0.39045828580856323 Num fake examples 6944 Num true examples 7136\n",
    "  Batch   480  of  2,790.    Elapsed: 0:02:52. Training loss. 0.4527665078639984 Num fake examples 7588 Num true examples 7772\n",
    "  Batch   520  of  2,790.    Elapsed: 0:03:06. Training loss. 0.3530610203742981 Num fake examples 8219 Num true examples 8421\n",
    "  Batch   560  of  2,790.    Elapsed: 0:03:20. Training loss. 0.3524516820907593 Num fake examples 8850 Num true examples 9070\n",
    "  Batch   600  of  2,790.    Elapsed: 0:03:35. Training loss. 0.43077731132507324 Num fake examples 9458 Num true examples 9742\n",
    "  Batch   640  of  2,790.    Elapsed: 0:03:49. Training loss. 0.38389742374420166 Num fake examples 10070 Num true examples 10410\n",
    "  Batch   680  of  2,790.    Elapsed: 0:04:04. Training loss. 0.45578664541244507 Num fake examples 10691 Num true examples 11069\n",
    "  Batch   720  of  2,790.    Elapsed: 0:04:18. Training loss. 0.36289653182029724 Num fake examples 11287 Num true examples 11753\n",
    "  Batch   760  of  2,790.    Elapsed: 0:04:32. Training loss. 0.3468509018421173 Num fake examples 11890 Num true examples 12430\n",
    "  Batch   800  of  2,790.    Elapsed: 0:04:47. Training loss. 0.37163519859313965 Num fake examples 12506 Num true examples 13094\n",
    "  Batch   840  of  2,790.    Elapsed: 0:05:01. Training loss. 0.3543040156364441 Num fake examples 13129 Num true examples 13751\n",
    "  Batch   880  of  2,790.    Elapsed: 0:05:15. Training loss. 0.3925606906414032 Num fake examples 13765 Num true examples 14395\n",
    "  Batch   920  of  2,790.    Elapsed: 0:05:30. Training loss. 0.34768420457839966 Num fake examples 14362 Num true examples 15078\n",
    "  Batch   960  of  2,790.    Elapsed: 0:05:44. Training loss. 0.37259483337402344 Num fake examples 15011 Num true examples 15709\n",
    "  Batch 1,000  of  2,790.    Elapsed: 0:05:58. Training loss. 0.36220261454582214 Num fake examples 15600 Num true examples 16400\n",
    "  Batch 1,040  of  2,790.    Elapsed: 0:06:13. Training loss. 0.3525162935256958 Num fake examples 16222 Num true examples 17058\n",
    "  Batch 1,080  of  2,790.    Elapsed: 0:06:27. Training loss. 0.37029919028282166 Num fake examples 16839 Num true examples 17721\n",
    "  Batch 1,120  of  2,790.    Elapsed: 0:06:42. Training loss. 0.41004252433776855 Num fake examples 17433 Num true examples 18407\n",
    "  Batch 1,160  of  2,790.    Elapsed: 0:06:56. Training loss. 0.35565584897994995 Num fake examples 18083 Num true examples 19037\n",
    "  Batch 1,200  of  2,790.    Elapsed: 0:07:10. Training loss. 0.358317494392395 Num fake examples 18725 Num true examples 19675\n",
    "  Batch 1,240  of  2,790.    Elapsed: 0:07:25. Training loss. 0.36391720175743103 Num fake examples 19354 Num true examples 20326\n",
    "  Batch 1,280  of  2,790.    Elapsed: 0:07:39. Training loss. 0.39611053466796875 Num fake examples 19992 Num true examples 20968\n",
    "  Batch 1,320  of  2,790.    Elapsed: 0:07:53. Training loss. 0.37767261266708374 Num fake examples 20590 Num true examples 21650\n",
    "  Batch 1,360  of  2,790.    Elapsed: 0:08:08. Training loss. 0.36601346731185913 Num fake examples 21200 Num true examples 22320\n",
    "  Batch 1,400  of  2,790.    Elapsed: 0:08:22. Training loss. 0.39152994751930237 Num fake examples 21821 Num true examples 22979\n",
    "  Batch 1,440  of  2,790.    Elapsed: 0:08:36. Training loss. 0.34792065620422363 Num fake examples 22438 Num true examples 23642\n",
    "  Batch 1,480  of  2,790.    Elapsed: 0:08:51. Training loss. 0.3566075265407562 Num fake examples 23062 Num true examples 24298\n",
    "  Batch 1,520  of  2,790.    Elapsed: 0:09:05. Training loss. 0.40325725078582764 Num fake examples 23669 Num true examples 24971\n",
    "  Batch 1,560  of  2,790.    Elapsed: 0:09:19. Training loss. 0.3535035252571106 Num fake examples 24273 Num true examples 25647\n",
    "  Batch 1,600  of  2,790.    Elapsed: 0:09:34. Training loss. 0.3400809168815613 Num fake examples 24907 Num true examples 26293\n",
    "  Batch 1,640  of  2,790.    Elapsed: 0:09:48. Training loss. 0.36527925729751587 Num fake examples 25552 Num true examples 26928\n",
    "  Batch 1,680  of  2,790.    Elapsed: 0:10:03. Training loss. 0.3765728771686554 Num fake examples 26205 Num true examples 27555\n",
    "  Batch 1,720  of  2,790.    Elapsed: 0:10:17. Training loss. 0.37866002321243286 Num fake examples 26854 Num true examples 28186\n",
    "  Batch 1,760  of  2,790.    Elapsed: 0:10:31. Training loss. 0.3873828649520874 Num fake examples 27457 Num true examples 28863\n",
    "  Batch 1,800  of  2,790.    Elapsed: 0:10:46. Training loss. 0.42301812767982483 Num fake examples 28058 Num true examples 29542\n",
    "  Batch 1,840  of  2,790.    Elapsed: 0:11:00. Training loss. 0.39517146348953247 Num fake examples 28683 Num true examples 30197\n",
    "  Batch 1,880  of  2,790.    Elapsed: 0:11:14. Training loss. 0.3877638280391693 Num fake examples 29333 Num true examples 30827\n",
    "  Batch 1,920  of  2,790.    Elapsed: 0:11:29. Training loss. 0.42093420028686523 Num fake examples 29966 Num true examples 31474\n",
    "  Batch 1,960  of  2,790.    Elapsed: 0:11:43. Training loss. 0.3477022051811218 Num fake examples 30599 Num true examples 32121\n",
    "  Batch 2,000  of  2,790.    Elapsed: 0:11:58. Training loss. 0.3832406997680664 Num fake examples 31209 Num true examples 32791\n",
    "  Batch 2,040  of  2,790.    Elapsed: 0:12:12. Training loss. 0.3847275376319885 Num fake examples 31816 Num true examples 33464\n",
    "  Batch 2,080  of  2,790.    Elapsed: 0:12:26. Training loss. 0.44686731696128845 Num fake examples 32430 Num true examples 34130\n",
    "  Batch 2,120  of  2,790.    Elapsed: 0:12:41. Training loss. 0.3739515244960785 Num fake examples 33077 Num true examples 34763\n",
    "  Batch 2,160  of  2,790.    Elapsed: 0:12:55. Training loss. 0.4164060354232788 Num fake examples 33695 Num true examples 35425\n",
    "  Batch 2,200  of  2,790.    Elapsed: 0:13:09. Training loss. 0.338975191116333 Num fake examples 34336 Num true examples 36064\n",
    "  Batch 2,240  of  2,790.    Elapsed: 0:13:24. Training loss. 0.44573354721069336 Num fake examples 34960 Num true examples 36720\n",
    "  Batch 2,280  of  2,790.    Elapsed: 0:13:38. Training loss. 0.3565433621406555 Num fake examples 35582 Num true examples 37378\n",
    "  Batch 2,320  of  2,790.    Elapsed: 0:13:52. Training loss. 0.390402615070343 Num fake examples 36196 Num true examples 38044\n",
    "  Batch 2,360  of  2,790.    Elapsed: 0:14:07. Training loss. 0.34158560633659363 Num fake examples 36783 Num true examples 38737\n",
    "  Batch 2,400  of  2,790.    Elapsed: 0:14:21. Training loss. 0.3550685942173004 Num fake examples 37383 Num true examples 39417\n",
    "  Batch 2,440  of  2,790.    Elapsed: 0:14:35. Training loss. 0.349115252494812 Num fake examples 37979 Num true examples 40101\n",
    "  Batch 2,480  of  2,790.    Elapsed: 0:14:50. Training loss. 0.37094205617904663 Num fake examples 38608 Num true examples 40752\n",
    "  Batch 2,520  of  2,790.    Elapsed: 0:15:04. Training loss. 0.41739729046821594 Num fake examples 39228 Num true examples 41412\n",
    "  Batch 2,560  of  2,790.    Elapsed: 0:15:18. Training loss. 0.38308826088905334 Num fake examples 39854 Num true examples 42066\n",
    "  Batch 2,600  of  2,790.    Elapsed: 0:15:33. Training loss. 0.38343578577041626 Num fake examples 40464 Num true examples 42736\n",
    "  Batch 2,640  of  2,790.    Elapsed: 0:15:47. Training loss. 0.38801664113998413 Num fake examples 41081 Num true examples 43399\n",
    "  Batch 2,680  of  2,790.    Elapsed: 0:16:02. Training loss. 0.38084009289741516 Num fake examples 41686 Num true examples 44074\n",
    "  Batch 2,720  of  2,790.    Elapsed: 0:16:16. Training loss. 0.334621787071228 Num fake examples 42322 Num true examples 44718\n",
    "  Batch 2,760  of  2,790.    Elapsed: 0:16:30. Training loss. 0.35193151235580444 Num fake examples 42972 Num true examples 45348\n",
    "\n",
    "  Average training loss: 0.38\n",
    "  Training epcoh took: 0:16:41\n",
    "\n",
    "Running Validation...\n",
    "  Accuracy: 0.51\n",
    "  Validation Loss: 0.38\n",
    "  Validation took: 0:01:41\n",
    "\n",
    "Training complete!\n",
    "Total training took 1:13:34 (h:mm:ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f245f-8243-49c7-ba4f-676e393fcf46",
   "metadata": {},
   "source": [
    " # What I attempted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b41444-2600-45d5-b263-cdb93844b9e6",
   "metadata": {},
   "source": [
    "### Learning Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884987c3-77ce-4cb2-a203-71d240b7a41d",
   "metadata": {},
   "source": [
    "To improve the accuracy of the BERT model using variations in the optimizer setup, I experimented with several adjustments. First, I fine-tuned the learning rate (lr) by testing values slightly higher or lower than the default (e.g., 1e-5 to 3e-5) to find an optimal setting that balanced convergence speed and stability. Next, I adjusted the epsilon (eps) parameter, which is the term added for numerical stability in the denominator during optimization, to ensure it suited the scale of gradients in my task. Using smaller values (e.g., 1e-9) enhanced precision but introduced some instability, while larger ones (e.g., 1e-7) smoothed optimization at the cost of precision. I also experimented with gradient clipping to prevent exploding gradients, particularly when using dynamic inputs or large batch sizes. I systematically combinied these tweaks and monitored validation accuracy.\n",
    "\n",
    "Attempts\n",
    "```\n",
    "1.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=3e-5,  # Experimenting with a slightly higher learning rate\n",
    "                  eps=1e-8  # Default epsilon\n",
    "                 )\n",
    "\n",
    "2.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5,  # Experimenting with a slightly lower learning rate\n",
    "                  eps=1e-8\n",
    "                 )\n",
    "\n",
    "3.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,\n",
    "                  eps=1e-9  # Using a smaller epsilon for higher precision\n",
    "                 )\n",
    "\n",
    "4.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,\n",
    "                  eps=1e-7  # Using a larger epsilon to enhance stability\n",
    "                 )\n",
    "\n",
    "5.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,\n",
    "                  eps=1e-8,\n",
    "                  weight_decay=0.01  # Adding a weight decay for regularization\n",
    "                 )\n",
    "\n",
    "6.\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,\n",
    "                  eps=1e-8,\n",
    "                  weight_decay=0.001  # Using a smaller weight decay\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692792d-2b47-42f1-855a-35d3769bbad4",
   "metadata": {},
   "source": [
    "## Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195b49b-a7bd-4a93-81cd-a1ff70c07ae1",
   "metadata": {},
   "source": [
    "I experimented with different batch sizes to optimize the training process for my BERT model. Initially, I followed the authors' recommendation of using batch sizes of 16 and 32, which are commonly suitable for fine-tuning tasks. I then tried smaller batch sizes, like 8, to handle memory constraints and improve gradient updates for small datasets. For larger datasets and available memory, I tested higher batch sizes, such as 64, to speed up training and stabilize the optimization process. \n",
    "```\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ba70f-641e-4d10-a295-1dba601744b8",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduler and Epochs\n",
    "I added and adjusted the learning rate scheduler to optimize the training process and prevent overfitting while fine-tuning the BERT model. Initially, I used the get_linear_schedule_with_warmup function, starting with the recommended parameters for warmup steps and total training steps. Then, I experimented with different numbers of epochs, total steps, and the proportion of warmup steps to evaluate the impact on model performance and training stability.\n",
    "```\n",
    "1.\n",
    "num_warmup_steps = int(0.2 * total_steps)  # 20% warmup\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=num_warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "2.\n",
    "epochs = 3  # Reduced number of epochs\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "num_warmup_steps = int(0.2 * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=num_warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "3.\n",
    "epochs = 5  # Increased number of epochs\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "num_warmup_steps = int(0.2 * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=num_warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "4.\n",
    "# Smaller warmup (10%)\n",
    "num_warmup_steps = int(0.1 * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=num_warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "5.\n",
    "# Larger warmup (30%)\n",
    "num_warmup_steps = int(0.3 * total_steps)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=num_warmup_steps, \n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be910b-9949-406d-8550-6620575d14db",
   "metadata": {},
   "source": [
    "## Step Limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e572ce6-4a2b-4ba6-a599-9a3710fa1de6",
   "metadata": {},
   "source": [
    "I applied the same step limit adjustment to both my training and validation loops, starting with a limit of 8,000 steps and later increasing it to 20,000. I attempted this so the model had more exposure to the data during training and was evaluated on a broader portion of the validation set\n",
    "\n",
    "```\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    if step > 8000:  # Stop training after 8,000 steps\n",
    "        break\n",
    "\n",
    "for step, batch in enumerate(validation_dataloader):\n",
    "    if step > 8000:  # Stop validation after 8,000 steps\n",
    "        break\n",
    "    # Validation logic here\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    if step > 20000:  # Stop training after 20,000 steps\n",
    "        break\n",
    "\n",
    "for step, batch in enumerate(validation_dataloader):\n",
    "    if step > 20000:  # Stop validation after 20,000 steps\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7bb6e-f959-4c9a-bef5-a4b6d86a8e3a",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490071e-0ce7-4b1c-8fbd-146dd1b77df2",
   "metadata": {},
   "source": [
    "### Still Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3142116-b2b7-43fb-9168-85bc38eaf397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
